{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1pxg6ywI6EEw"
   },
   "source": [
    "|<h2>Course:</h2>|<h1><a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">A deep understanding of AI language model mechanisms</a></h1>|\n",
    "|-|:-:|\n",
    "|<h2>Part 1:</h2>|<h1>Tokenizations and embeddings<h1>|\n",
    "|<h2>Section:</h2>|<h1>Words to tokens to numbers<h1>|\n",
    "|<h2>Lecture:</h2>|<h1><b>CodeChallenge HELPER: Tokenizing The Time Machine<b></h1>|\n",
    "\n",
    "<br>\n",
    "\n",
    "<h5><b>Teacher:</b> Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h5>\n",
    "<h5><b>Course URL:</b> <a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">udemy.com/course/dullms_x/?couponCode=202508</a></h5>\n",
    "<i>Using the code without the course may lead to confusion or errors.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7k510WhK6Dpe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "lwgCppyRKogB"
   },
   "outputs": [],
   "source": [
    "# typical libraries...\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for importing and working with texts\n",
    "import requests\n",
    "import re\n",
    "import string\n",
    "\n",
    "# adjust matplotlib defaults to personal preferences\n",
    "import matplotlib_inline.backend_inline\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3xNZfqxm6m4I"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fEFbCZ8FLEu8"
   },
   "source": [
    "# Exercise 1: Get and prepare the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "EPRfkKgHLEsE"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'(' was never closed (2342049220.py, line 9)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mtext = re.compile().sub(\u001b[39m\n                           ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m '(' was never closed\n"
     ]
    }
   ],
   "source": [
    "# get raw text from internet\n",
    "text = requests.get('https://www.gutenberg.org/files/35/35-0.txt').text\n",
    "\n",
    "# character strings to replace with space\n",
    "strings2replace = [ '\\r\\n\\r\\nâ\\x80\\x9c','â\\x80\\x9c','â\\x80\\x9d','\\r\\n','â\\x80\\x94','â\\x80\\x99','â\\x80\\x98','_', ]\n",
    "\n",
    "# use regular expression (re) to replace those strings with space\n",
    "for str2match in strings2replace:\n",
    "  text = re.compile().sub(\n",
    "\n",
    "# remove non-ASCII characters and numbers, and make lower-case\n",
    "text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
    "text = re.sub(r'\\d+','',text).make this lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YM_OBLi7zptg"
   },
   "outputs": [],
   "source": [
    "# split into words that contain >1 character\n",
    "words = re.split(fr'[{string.punctuation}\\s]+',text)\n",
    "words = [item.strip() for item in words if item.strip()]\n",
    "words = # save only the words with >1 chars\n",
    "\n",
    "# create the vocab / lexicon\n",
    "vocab = # a sorted set\n",
    "nWords =\n",
    "nLex ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Belr9eoCLTcV"
   },
   "outputs": [],
   "source": [
    "# create the encoder/decoding mapping dictionaries\n",
    "word2idx = {w:i for i,w in enumerate()}\n",
    "idx2word ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2HYTeIawLEOk"
   },
   "outputs": [],
   "source": [
    "# create encoder and decoder functions\n",
    "def encoder(words,encode_dict):\n",
    "\n",
    "  # loop through the words and find their token in the vocab\n",
    "  idxs = np.zeros(len(words),dtype=int)\n",
    "  for i,w in enumerate(words):\n",
    "    idxs\n",
    "  return\n",
    "\n",
    "# and the decoder function\n",
    "def decoder(idxs,decode_dict):\n",
    "  return ' '.join(# the dictionary items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7R9AB9nXY3Ru"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O59NxW2pY3U2"
   },
   "source": [
    "# Exercise 2: A random walk through the Time Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MpnKCGlNYyKn"
   },
   "outputs": [],
   "source": [
    "# random tokens\n",
    "randomTokens =\n",
    "\n",
    "# test with random token indices\n",
    "print(f'Random tokens: \\n\\t{randomTokens}\\n')\n",
    "print(f'Decoded text: \\n\\t{"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dLNWiOh5V2zo"
   },
   "outputs": [],
   "source": [
    "# A brief aside on Brownian noise\n",
    "brownNoise = np.cumsum(np.random.choice([-1,1],3000))\n",
    "\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.plot(brownNoise,'k')\n",
    "plt.gca().set(xlim=[0,len(brownNoise)],xlabel='\"Time\" (?)',ylabel='Signal amplitude',title='Brownian noise')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cIpqrE5rKGbe"
   },
   "outputs": [],
   "source": [
    "# Brownian noise\n",
    "brownNoise = np.cumsum( # a random sequence of +1 and -1\n",
    "print(brownNoise)\n",
    "\n",
    "BrownianRandomTokens = brownNoise +\n",
    "print(BrownianRandomTokens)\n",
    "print('')\n",
    "\n",
    "# test with random token indices\n",
    "print(f'Brownian random tokens\n",
    "print(f'Decoded text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gEzmF7q5LXeD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NXFIvKbFLXa1"
   },
   "source": [
    "# Exercise 3: Distribution of word lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YFZwHX25MQuD"
   },
   "outputs": [],
   "source": [
    "# loop through the words and count the characters per word\n",
    "numChars =\n",
    "for i,w in enumerate(words):\n",
    "  numChars[i] =\n",
    "\n",
    "# now count the number of words with those characters\n",
    "charCounts =\n",
    "for i in\n",
    "  charCounts[i] = np.sum(numChars==i)\n",
    "\n",
    "\n",
    "# and plot\n",
    "_,axs = plt.subplots(2,1,figsize=(10,7))\n",
    "axs[0].scatter(range(nWords),numChars,marker='.',s=10,c=np.linspace(.1,.9,len(numChars)),alpha=.4)\n",
    "axs[0].set(yticks=range(1,int(np.max(numChars))),xlabel='Token index',xlim=[-15,nWords+15],\n",
    "           ylabel='Number of characters',title='Character count by token index')\n",
    "\n",
    "axs[1].bar(range(len(charCounts)),charCounts,edgecolor='k',color=[.9,.7,.9])\n",
    "axs[1].set(xticks=range(1,len(charCounts)),xlim=[0,len(charCounts)],xlabel='Number of characters',\n",
    "           ylabel='Token count',title='Histogram of character count frequencies')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gcbcj7JsLXX6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SJacP80VRwbV"
   },
   "source": [
    "# Exercise 4: Encode a novel sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "unIc2KwtRaGt"
   },
   "outputs": [],
   "source": [
    "# the text to decode\n",
    "sentence = 'The space aliens came to Earth to steal watermelons and staplers.'\n",
    "\n",
    "# preprocess (remove punctuation, make lower-case, split into words)\n",
    "words_new = re.split(f'[,.\\s]+',\n",
    "\n",
    "# remove empty items\n",
    "words_new = [item.strip() for item in words_new if item.strip()]\n",
    "words_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nVrNpUxeVQgi"
   },
   "outputs": [],
   "source": [
    "# tokenize (uh oh...)\n",
    "encoder(words_new,word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pkZSVYVbgJE6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GzV3-uvcgJCh"
   },
   "source": [
    "# Exercise 5: Create a new encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z_8CpZRLRaEE"
   },
   "outputs": [],
   "source": [
    "# need to update the vocab\n",
    "word2idx_new = word2idx.copy()\n",
    "idx2word_new = idx2word.copy()\n",
    "\n",
    "# add an entry for unknown words\n",
    "word2idx_new['<|unk|>'] =\n",
    "idx2word_new... = '<|unk|>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1u6Vb4_SdDiN"
   },
   "outputs": [],
   "source": [
    "# need a new encoder function\n",
    "def encoder_new(words,encode_dict):\n",
    "\n",
    "  # initialize a vector of numerical indices\n",
    "  idxs = np.zeros(len(words),dtype=int)\n",
    "\n",
    "  # loop through the words and find their token in the vocab\n",
    "  for i,w in enumerate(\n",
    "    if w in encode_dict:\n",
    "\n",
    "    else:\n",
    "\n",
    "\n",
    "  # return the results!\n",
    "  return idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H6TZbghCRaBU"
   },
   "outputs": [],
   "source": [
    "# try again\n",
    "tokenidx = encoder_new(words_new,word2idx_new)\n",
    "tokenidx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dKDT_rlPRZ8S"
   },
   "outputs": [],
   "source": [
    "# need a new decoder function?\n",
    "decoder(tokenidx,idx2word_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AFEeR0URLXSd"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "3.12.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
